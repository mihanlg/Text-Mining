{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymorphy2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "politics = './politics/'\n",
    "sports = './sports/'\n",
    "unclassified = './unclassified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = np.array([u'Politics', u'Sports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_docs = []\n",
    "train_labels = []\n",
    "test_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train(cat, label):\n",
    "    global train_docs, train_labels\n",
    "    for filename in os.listdir(cat):\n",
    "        if filename.startswith('news'):\n",
    "            with open(cat+filename, 'r') as f:\n",
    "                train_docs.append(f.read().decode('utf-8'))\n",
    "                train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test(cat):\n",
    "    global test_docs\n",
    "    for filename in os.listdir(cat):\n",
    "        if filename.startswith('news'):\n",
    "            with open(cat+filename, 'r') as f:\n",
    "                test_docs.append(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_train(politics, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_train(sports, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_test(unclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news_antifashisty',\n",
       " 'news_britansky_ministr',\n",
       " 'news_dic_advocat',\n",
       " 'news_gol_azmuna',\n",
       " 'news_kirgiziya',\n",
       " 'news_lavrov_o_prosbe_kieva',\n",
       " 'news_net_otsrochki',\n",
       " 'news_promes_dumayu',\n",
       " 'news_savchenko']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [filename for filename in os.listdir(unclassified) if filename.startswith('news')]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = [0, 0, 1, 1, 0, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_splitter = re.compile(r'\\w+', re.U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    global cache\n",
    "    lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "    result = []\n",
    "    for word in words_splitter.findall(text):\n",
    "        word_hash = hash(word)\n",
    "        if word_hash not in cache:\n",
    "            cache[word_hash] = lemmatizer.parse(word)[0].normal_form            \n",
    "        result.append(cache[word_hash])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_docs).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_clf = MultinomialNB(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(X_test, with_log = True):\n",
    "    global mnb_clf\n",
    "    if with_log:\n",
    "        predicted = mnb_clf.predict_log_proba(X_test)\n",
    "    else:\n",
    "        predicted = mnb_clf.predict_proba(X_test)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_predicted(n, predicted, text):\n",
    "    global names, classes, test_docs\n",
    "    print u'Weights for class \"{0}\": {1}'.format(classes[0], predicted[n][0])\n",
    "    print u'Weights for class \"{0}\": {1}'.format(classes[1], predicted[n][1])\n",
    "    print\n",
    "    print u'Predicted class for text: {0}\\n{1}\\n{2}...'.format(classes[np.argmax(predicted[n])],\n",
    "                                                              u'-'*40, text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    global vectorizer\n",
    "    X = vectorizer.transform([text])\n",
    "    predicted = predict_proba(X)\n",
    "    print_predicted(0, predicted, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -0.236280304978\n",
      "Weights for class \"Sports\": -1.55855149695\n",
      "\n",
      "Predicted class for text: Politics\n",
      "----------------------------------------\n",
      "президент России...\n"
     ]
    }
   ],
   "source": [
    "classify_text(u'президент России')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -0.447018487884\n",
      "Weights for class \"Sports\": -1.02035232641\n",
      "\n",
      "Predicted class for text: Politics\n",
      "----------------------------------------\n",
      "доклад по теме...\n"
     ]
    }
   ],
   "source": [
    "classify_text(u'доклад по теме')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -2.00041637266\n",
      "Weights for class \"Sports\": -0.14534830389\n",
      "\n",
      "Predicted class for text: Sports\n",
      "----------------------------------------\n",
      "футбольная команда...\n"
     ]
    }
   ],
   "source": [
    "classify_text(u'футбольная команда')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -0.880523807043\n",
      "Weights for class \"Sports\": -0.535401318063\n",
      "\n",
      "Predicted class for text: Sports\n",
      "----------------------------------------\n",
      "игровое поле...\n"
     ]
    }
   ],
   "source": [
    "classify_text(u'игровое поле')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -0.125107774807\n",
      "Weights for class \"Sports\": -2.14048152234\n",
      "\n",
      "Predicted class for text: Politics\n",
      "----------------------------------------\n",
      "Британский министр иностранных дел прокомментировал годовщину воссоединения Крыма с Россией. По его словам, полуостров должен стать частью Украины. \n",
      "\n",
      "Великобритания\n",
      "Единая Россия\n",
      "Крым\n",
      "Филип Хаммонд, глава МИД Великобритании: «Наше послание России ясно — присоединение Крыма в марте 2014 года было незаконным, остается оно незаконным и в марте 2015 года».\n",
      "\n",
      "По его словам, такое поведение России угрожает международной безопасности. Филип Хаммонд подчеркнул, что Британия не признает прошлогодний рефер...\n"
     ]
    }
   ],
   "source": [
    "print_predicted(1, predict_proba(X_test), test_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -1.96384033471\n",
      "Weights for class \"Sports\": -0.151193324396\n",
      "\n",
      "Predicted class for text: Sports\n",
      "----------------------------------------\n",
      "ДИК АДВОКАТ: \"САНДЕРЛЕНД\" ЗАСЛУЖИВАЛ БОЛЬШЕГО\"\n",
      "\n",
      "Главный тренер \"Сандерленда\" Дик Адвокат после поражения от \"Вест Хэма\" (0:1) в 30-м туре чемпионата Англии остался недоволен результатом, однако отметил, что игра указала на недостатки. По словам голландца, если их исправить, то в следующем матче против \"Ньюкасла\" можно добиться победы. Напомним, для бывшего наставника \"Зенита\" прошедшая игра стала дебютной на посту главного тренера Сандерленда.\n",
      "\n",
      "– Мы заслуживали большего, – цитирует Адвоката BBC....\n"
     ]
    }
   ],
   "source": [
    "print_predicted(2, predict_proba(X_test), test_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -2.97835945911\n",
      "Weights for class \"Sports\": -0.0522160673529\n",
      "\n",
      "Predicted class for text: Sports\n",
      "----------------------------------------\n",
      "Гол Азмуна принес \"Ростову\" победу над \"Кубанью\" со счетом 2:1.\n",
      "\n",
      "В Ростове-на-Дону на стадионе \"Олимп-2\" состоялся заключительный матч 19 тура чемпионата России по футболу. Аутсайдер премьер-лиги ФК \"Ростов\" принимал на своем поле \"Кубань\" из Краснодара, которая на начало матча находилась на восьмом месте турнирной таблицы. Встреча закончилась со счетом 2:1. Все мячи были забиты во втором тайме.\n",
      "\n",
      "Отметим, что еще задолго до встречи болельщики и сами игроки назвали встречу \"Кубани\" и \"Ростова\" - ...\n"
     ]
    }
   ],
   "source": [
    "print_predicted(3, predict_proba(X_test), test_docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for class \"Politics\": -0.145483241225\n",
      "Weights for class \"Sports\": -1.99955426514\n",
      "\n",
      "Predicted class for text: Politics\n",
      "----------------------------------------\n",
      "Киргизия намерена вступить в ЕАЭС до 9 мая.\n",
      "\n",
      "В Петербурге в понедельник прошли переговоры президентов России и Киргизии Владимира Путина и Алмазбека Атамбаева. В числе прочего, обсуждался процесс вхождения Киргизии в Евразийский экономический союз. По мнению российского лидера, чем быстрее будет выполнена эта задача, тем лучше.\n",
      "\n",
      "Планы укрепления сотрудничества России и Киргизии обсудили в понедельник президенты двух стран. Переговоры Владимира Путина и Алмазбека Атамбаева прошли в Константиновск...\n"
     ]
    }
   ],
   "source": [
    "print_predicted(4, predict_proba(X_test), test_docs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
